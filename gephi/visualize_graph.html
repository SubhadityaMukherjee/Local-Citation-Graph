<html>
    <head>
        <meta charset="utf-8">
        
            <script src="lib/bindings/utils.js"></script>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css" integrity="sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
            <script src="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js" integrity="sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            
                <link href="lib/tom-select/tom-select.css" rel="stylesheet">
                <script src="lib/tom-select/tom-select.complete.min.js"></script>
            
        
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->
        <link
          href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6"
          crossorigin="anonymous"
        />
        <script
          src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf"
          crossorigin="anonymous"
        ></script>


        <center>
          <h1></h1>
        </center>
        <style type="text/css">

             #mynetwork {
                 width: 100%;
                 height: 600px;
                 background-color: #222222;
                 border: 1px solid lightgray;
                 position: relative;
                 float: left;
             }

             

             
             #config {
                 float: left;
                 width: 400px;
                 height: 600px;
             }
             

             
        </style>
    </head>


    <body>
        <div class="card" style="width: 100%">
            
                <div id="select-menu" class="card-header">
                    <div class="row no-gutters">
                        <div class="col-10 pb-2">
                            <select
                            class="form-select"
                            aria-label="Default select example"
                            onchange="selectNode([value]);"
                            id="select-node"
                            placeholder="Select node..."
                            >
                                <option selected>Select a Node by ID</option>
                                
                                    <option value="embedding human knowledge into deep neural network via attention map">embedding human knowledge into deep neural network via attention map</option>
                                
                                    <option value="gradcam visual explanations from deep networks via gradientbased localization">gradcam visual explanations from deep networks via gradientbased localization</option>
                                
                                    <option value="network in network">network in network</option>
                                
                                    <option value="attention is all you need">attention is all you need</option>
                                
                                    <option value="is object localization for free weaklysupervised learning with convolutional neural networks">is object localization for free weaklysupervised learning with convolutional neural networks</option>
                                
                                    <option value="couplformerrethinking vision transformer with coupling attention map">couplformerrethinking vision transformer with coupling attention map</option>
                                
                                    <option value="attention augmented convolutional networks">attention augmented convolutional networks</option>
                                
                                    <option value="an image is worth x words transformers for image recognition at scale">an image is worth x words transformers for image recognition at scale</option>
                                
                                    <option value="gradcam improved visual explanations for deep convolutional networks">gradcam improved visual explanations for deep convolutional networks</option>
                                
                                    <option value="on the overlap between gradcam saliency maps and explainable visual features in skin cancer images">on the overlap between gradcam saliency maps and explainable visual features in skin cancer images</option>
                                
                                    <option value="on the importance of visual context for data augmentation in scene understanding">on the importance of visual context for data augmentation in scene understanding</option>
                                
                                    <option value="random erasing data augmentation">random erasing data augmentation</option>
                                
                                    <option value="modeling visual context is key to augmenting object detection datasets">modeling visual context is key to augmenting object detection datasets</option>
                                
                                    <option value="bert pretraining of deep bidirectional transformers for language understanding">bert pretraining of deep bidirectional transformers for language understanding</option>
                                
                                    <option value="language models are fewshot learners">language models are fewshot learners</option>
                                
                                    <option value="swin transformer v scaling up capacity and resolution">swin transformer v scaling up capacity and resolution</option>
                                
                            </select>
                        </div>
                        <div class="col-2 pb-2">
                            <button type="button" class="btn btn-primary btn-block" onclick="neighbourhoodHighlight({nodes: []});">Reset Selection</button>
                        </div>
                    </div>
                </div>
            
            
              <div id="filter-menu" class="card-header">
                <div class="row no-gutters">
                  <div class="col-3 pb-2">
                    <select
                            class="form-select"
                            aria-label="Default select example"
                            onchange="updateFilter(value, 'item')"
                            id="select-item"
                        >
                        <option value="">Select a network item</option>
                        <option value="edge">edge</option>
                        <option value="node">node</option>
                    </select>
                  </div>
                  <div class="col-3 pb-2">
                    <select
                            class="form-select"
                            aria-label="Default select example"
                            onchange="updateFilter(value, 'property')"
                            id="select-property"
                        >
                        <option value="">Select a property...</option>
                    </select>
                  </div>
                  <div class="col-3 pb-2">
                    <select
                            class="form-select"
                            aria-label="Default select example"
                            id="select-value"
                        >
                        <option value="">Select value(s)...</option>
                    </select>
                  </div>
                  <div class="col-1 pb-2">
                    <button type="button" class="btn btn-primary btn-block" onclick="highlightFilter(filter);">Filter</button>
                  </div>
                  <div class="col-2 pb-2">
                    <button type="button" class="btn btn-primary btn-block" onclick="clearFilter(true)">Reset Selection</button>
                  </div>
                </div>
              </div>
            
            <div id="mynetwork" class="card-body"></div>
        </div>

        
        
            <div id="config"></div>
        

        <script type="text/javascript">

              // initialize global variables.
              var edges;
              var nodes;
              var allNodes;
              var allEdges;
              var nodeColors;
              var originalNodes;
              var network;
              var container;
              var options, data;
              var filter = {
                  item : '',
                  property : '',
                  value : []
              };

              
                  new TomSelect("#select-node",{
                      create: false,
                      sortField: {
                          field: "text",
                          direction: "asc"
                      }
                  });
              

              
                  // explicitly using onItemAdd and this function as we need to save multiple values
                  let updateValueFilter = function() {
                      return function () {
                      filter['value'].push(arguments[0])
                      }
                  }

                  let valueControl = new TomSelect("#select-value",{
                      maxItems: null,
                      valueField: 'id',
                      labelField: 'title',
                      searchField: 'title',
                      create: false,
                      sortField: {
                          field: "text",
                          direction: "asc"
                      },
                      onItemAdd: updateValueFilter()
                  });

                  let addValues = function() {
                      return function () {
                          // clear the current value options and add the selected attribute values
                          // tom-select handles duplicates
                          let selectedProperty = arguments[0];
                          valueControl.clear();
                          valueControl.clearOptions();
                          filter['value'] = []
                          if (filter['item'] === 'node') {
                              for (let each in allNodes) {
                                  valueControl.addOption({
                                      id:allNodes[each][selectedProperty],
                                      title:allNodes[each][selectedProperty]
                                  })
                              }
                          }
                          else if (filter['item'] === 'edge') {
                              for (let each in allEdges) {
                                  valueControl.addOption({
                                      id:allEdges[each][selectedProperty],
                                      title:allEdges[each][selectedProperty]
                                  })
                              }
                          }
                      }
                  };

                  let propControl = new TomSelect("#select-property",{
                      valueField: 'id',
                      labelField: 'title',
                      searchField: 'title',
                      create: false,
                      sortField: {
                          field: "text",
                          direction: "asc"
                      },
                      onItemAdd: addValues()
                  });

                  let addProperties = function() {
                      return function () {
                          // loops through the selected network item and adds the attributes to dropdown
                          // tom-select handles duplicates
                          clearFilter(false)
                          if (arguments[0] === 'edge') {
                              for (let each in allEdges) {
                                  if (allEdges.hasOwnProperty(each)) {
                                      for (let eachProp in allEdges[each]) {
                                          if (allEdges[each].hasOwnProperty(eachProp)) {
                                              propControl.addOption({id: eachProp, title: eachProp})
                                          }
                                      }
                                  }
                              }
                          }
                          else if (arguments[0] === 'node') {
                              for (let each in allNodes) {
                                  if (allNodes.hasOwnProperty(each)) {
                                      for (let eachProp in allNodes[each]) {
                                          if (allNodes[each].hasOwnProperty(eachProp)
                                              && (eachProp !== 'hidden' && eachProp !== 'savedLabel'
                                                  && eachProp !== 'hiddenLabel')) {
                                              propControl.addOption({id: eachProp, title: eachProp})

                                          }
                                      }
                                  }
                              }
                          }
                      }
                  };

                  let itemControl = new TomSelect("#select-item",{
                      create: false,
                      sortField:{
                          field: "text",
                          direction: "asc"
                      },
                      onItemAdd: addProperties()
                  });

                  function clearFilter(reset) {
                      // utility function to clear all the selected filter options
                      // if reset is set to true, the existing filter will be removed
                      // else, only the dropdown options are cleared
                      propControl.clear();
                      propControl.clearOptions();
                      valueControl.clear();
                      valueControl.clearOptions();
                      filter = {
                          item : '',
                          property : '',
                          value : []
                      }
                      if (reset) {
                          itemControl.clear();
                          filterHighlight({nodes: []})
                      }
                  }

                  function updateFilter(value, key) {
                      // key could be 'item' or 'property' and value is as selected in dropdown
                      filter[key] = value
                  }

              

              // This method is responsible for drawing the graph, returns the drawn network
              function drawGraph() {
                  var container = document.getElementById('mynetwork');

                  

                  // parsing and collecting nodes and edges from the python
                  nodes = new vis.DataSet([{"color": "#97c2fc", "font": {"color": "white"}, "id": "embedding human knowledge into deep neural network via attention map", "label": "embedding human knowledge into deep neural network via attention map", "shape": "dot", "size": 10}, {"color": "#97c2fc", "font": {"color": "white"}, "id": "gradcam visual explanations from deep networks via gradientbased localization", "label": "gradcam visual explanations from deep networks via gradientbased localization", "shape": "dot", "size": 10}, {"color": "#97c2fc", "font": {"color": "white"}, "id": "network in network", "label": "network in network", "shape": "dot", "size": 10}, {"color": "#97c2fc", "font": {"color": "white"}, "id": "attention is all you need", "label": "attention is all you need", "shape": "dot", "size": 10}, {"color": "#97c2fc", "font": {"color": "white"}, "id": "is object localization for free weaklysupervised learning with convolutional neural networks", "label": "is object localization for free weaklysupervised learning with convolutional neural networks", "shape": "dot", "size": 10}, {"color": "#97c2fc", "font": {"color": "white"}, "id": "couplformerrethinking vision transformer with coupling attention map", "label": "couplformerrethinking vision transformer with coupling attention map", "shape": "dot", "size": 10}, {"color": "#97c2fc", "font": {"color": "white"}, "id": "attention augmented convolutional networks", "label": "attention augmented convolutional networks", "shape": "dot", "size": 10}, {"color": "#97c2fc", "font": {"color": "white"}, "id": "an image is worth x words transformers for image recognition at scale", "label": "an image is worth x words transformers for image recognition at scale", "shape": "dot", "size": 10}, {"color": "#97c2fc", "font": {"color": "white"}, "id": "gradcam improved visual explanations for deep convolutional networks", "label": "gradcam improved visual explanations for deep convolutional networks", "shape": "dot", "size": 10}, {"color": "#97c2fc", "font": {"color": "white"}, "id": "on the overlap between gradcam saliency maps and explainable visual features in skin cancer images", "label": "on the overlap between gradcam saliency maps and explainable visual features in skin cancer images", "shape": "dot", "size": 10}, {"color": "#97c2fc", "font": {"color": "white"}, "id": "on the importance of visual context for data augmentation in scene understanding", "label": "on the importance of visual context for data augmentation in scene understanding", "shape": "dot", "size": 10}, {"color": "#97c2fc", "font": {"color": "white"}, "id": "random erasing data augmentation", "label": "random erasing data augmentation", "shape": "dot", "size": 10}, {"color": "#97c2fc", "font": {"color": "white"}, "id": "modeling visual context is key to augmenting object detection datasets", "label": "modeling visual context is key to augmenting object detection datasets", "shape": "dot", "size": 10}, {"color": "#97c2fc", "font": {"color": "white"}, "id": "bert pretraining of deep bidirectional transformers for language understanding", "label": "bert pretraining of deep bidirectional transformers for language understanding", "shape": "dot", "size": 10}, {"color": "#97c2fc", "font": {"color": "white"}, "id": "language models are fewshot learners", "label": "language models are fewshot learners", "shape": "dot", "size": 10}, {"color": "#97c2fc", "font": {"color": "white"}, "id": "swin transformer v scaling up capacity and resolution", "label": "swin transformer v scaling up capacity and resolution", "shape": "dot", "size": 10}]);
                  edges = new vis.DataSet([{"arrows": "to", "from": "embedding human knowledge into deep neural network via attention map", "to": "gradcam visual explanations from deep networks via gradientbased localization", "width": 1}, {"arrows": "to", "from": "embedding human knowledge into deep neural network via attention map", "to": "network in network", "width": 1}, {"arrows": "to", "from": "embedding human knowledge into deep neural network via attention map", "to": "attention is all you need", "width": 1}, {"arrows": "to", "from": "gradcam visual explanations from deep networks via gradientbased localization", "to": "is object localization for free weaklysupervised learning with convolutional neural networks", "width": 1}, {"arrows": "to", "from": "gradcam visual explanations from deep networks via gradientbased localization", "to": "network in network", "width": 1}, {"arrows": "to", "from": "couplformerrethinking vision transformer with coupling attention map", "to": "attention augmented convolutional networks", "width": 1}, {"arrows": "to", "from": "couplformerrethinking vision transformer with coupling attention map", "to": "attention is all you need", "width": 1}, {"arrows": "to", "from": "couplformerrethinking vision transformer with coupling attention map", "to": "an image is worth x words transformers for image recognition at scale", "width": 1}, {"arrows": "to", "from": "attention augmented convolutional networks", "to": "attention is all you need", "width": 1}, {"arrows": "to", "from": "is object localization for free weaklysupervised learning with convolutional neural networks", "to": "network in network", "width": 1}, {"arrows": "to", "from": "gradcam improved visual explanations for deep convolutional networks", "to": "is object localization for free weaklysupervised learning with convolutional neural networks", "width": 1}, {"arrows": "to", "from": "gradcam improved visual explanations for deep convolutional networks", "to": "network in network", "width": 1}, {"arrows": "to", "from": "on the overlap between gradcam saliency maps and explainable visual features in skin cancer images", "to": "gradcam visual explanations from deep networks via gradientbased localization", "width": 1}, {"arrows": "to", "from": "on the importance of visual context for data augmentation in scene understanding", "to": "random erasing data augmentation", "width": 1}, {"arrows": "to", "from": "on the importance of visual context for data augmentation in scene understanding", "to": "modeling visual context is key to augmenting object detection datasets", "width": 1}, {"arrows": "to", "from": "bert pretraining of deep bidirectional transformers for language understanding", "to": "attention is all you need", "width": 1}, {"arrows": "to", "from": "language models are fewshot learners", "to": "attention is all you need", "width": 1}, {"arrows": "to", "from": "swin transformer v scaling up capacity and resolution", "to": "random erasing data augmentation", "width": 1}, {"arrows": "to", "from": "swin transformer v scaling up capacity and resolution", "to": "attention is all you need", "width": 1}, {"arrows": "to", "from": "swin transformer v scaling up capacity and resolution", "to": "language models are fewshot learners", "width": 1}, {"arrows": "to", "from": "swin transformer v scaling up capacity and resolution", "to": "an image is worth x words transformers for image recognition at scale", "width": 1}]);

                  nodeColors = {};
                  allNodes = nodes.get({ returnType: "Object" });
                  for (nodeId in allNodes) {
                    nodeColors[nodeId] = allNodes[nodeId].color;
                  }
                  allEdges = edges.get({ returnType: "Object" });
                  // adding nodes and edges to the graph
                  data = {nodes: nodes, edges: edges};

                  var options = {
    "configure": {
        "enabled": true,
        "filter": [
            "physics"
        ]
    },
    "edges": {
        "color": {
            "inherit": true
        },
        "smooth": {
            "enabled": true,
            "type": "dynamic"
        }
    },
    "interaction": {
        "dragNodes": true,
        "hideEdgesOnDrag": false,
        "hideNodesOnDrag": false
    },
    "physics": {
        "enabled": true,
        "stabilization": {
            "enabled": true,
            "fit": true,
            "iterations": 1000,
            "onlyDynamicEdges": false,
            "updateInterval": 50
        }
    }
};

                  


                  
                  // if this network requires displaying the configure window,
                  // put it in its div
                  options.configure["container"] = document.getElementById("config");
                  

                  network = new vis.Network(container, data, options);

                  

                  
                    network.on("selectNode", neighbourhoodHighlight);
                  

                  


                  

                  return network;

              }
              drawGraph();
        </script>
    </body>
</html>