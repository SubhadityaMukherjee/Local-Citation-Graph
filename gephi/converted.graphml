<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"><key id="d0" for="edge" attr.name="weight" attr.type="long"/>
<graph edgedefault="directed"><node id="embedding human knowledge into deep neural network via attention map"/>
<node id="gradcam visual explanations from deep networks via gradientbased localization"/>
<node id="network in network"/>
<node id="attention is all you need"/>
<node id="couplformerrethinking vision transformer with coupling attention map"/>
<node id="attention augmented convolutional networks"/>
<node id="an image is worth x words transformers for image recognition at scale"/>
<node id="is object localization for free weaklysupervised learning with convolutional neural networks"/>
<node id="gradcam improved visual explanations for deep convolutional networks"/>
<node id="on the overlap between gradcam saliency maps and explainable visual features in skin cancer images"/>
<node id="on the importance of visual context for data augmentation in scene understanding"/>
<node id="random erasing data augmentation"/>
<node id="modeling visual context is key to augmenting object detection datasets"/>
<node id="bert pretraining of deep bidirectional transformers for language understanding"/>
<node id="language models are fewshot learners"/>
<node id="swin transformer v scaling up capacity and resolution"/>
<edge source="embedding human knowledge into deep neural network via attention map" target="gradcam visual explanations from deep networks via gradientbased localization">
  <data key="d0">1</data>
</edge>
<edge source="embedding human knowledge into deep neural network via attention map" target="network in network">
  <data key="d0">1</data>
</edge>
<edge source="embedding human knowledge into deep neural network via attention map" target="attention is all you need">
  <data key="d0">1</data>
</edge>
<edge source="gradcam visual explanations from deep networks via gradientbased localization" target="is object localization for free weaklysupervised learning with convolutional neural networks">
  <data key="d0">1</data>
</edge>
<edge source="gradcam visual explanations from deep networks via gradientbased localization" target="network in network">
  <data key="d0">1</data>
</edge>
<edge source="couplformerrethinking vision transformer with coupling attention map" target="attention augmented convolutional networks">
  <data key="d0">1</data>
</edge>
<edge source="couplformerrethinking vision transformer with coupling attention map" target="attention is all you need">
  <data key="d0">1</data>
</edge>
<edge source="couplformerrethinking vision transformer with coupling attention map" target="an image is worth x words transformers for image recognition at scale">
  <data key="d0">1</data>
</edge>
<edge source="attention augmented convolutional networks" target="attention is all you need">
  <data key="d0">1</data>
</edge>
<edge source="is object localization for free weaklysupervised learning with convolutional neural networks" target="network in network">
  <data key="d0">1</data>
</edge>
<edge source="gradcam improved visual explanations for deep convolutional networks" target="is object localization for free weaklysupervised learning with convolutional neural networks">
  <data key="d0">1</data>
</edge>
<edge source="gradcam improved visual explanations for deep convolutional networks" target="network in network">
  <data key="d0">1</data>
</edge>
<edge source="on the overlap between gradcam saliency maps and explainable visual features in skin cancer images" target="gradcam visual explanations from deep networks via gradientbased localization">
  <data key="d0">1</data>
</edge>
<edge source="on the importance of visual context for data augmentation in scene understanding" target="random erasing data augmentation">
  <data key="d0">1</data>
</edge>
<edge source="on the importance of visual context for data augmentation in scene understanding" target="modeling visual context is key to augmenting object detection datasets">
  <data key="d0">1</data>
</edge>
<edge source="bert pretraining of deep bidirectional transformers for language understanding" target="attention is all you need">
  <data key="d0">1</data>
</edge>
<edge source="language models are fewshot learners" target="attention is all you need">
  <data key="d0">1</data>
</edge>
<edge source="swin transformer v scaling up capacity and resolution" target="random erasing data augmentation">
  <data key="d0">1</data>
</edge>
<edge source="swin transformer v scaling up capacity and resolution" target="attention is all you need">
  <data key="d0">1</data>
</edge>
<edge source="swin transformer v scaling up capacity and resolution" target="language models are fewshot learners">
  <data key="d0">1</data>
</edge>
<edge source="swin transformer v scaling up capacity and resolution" target="an image is worth x words transformers for image recognition at scale">
  <data key="d0">1</data>
</edge>
</graph></graphml>